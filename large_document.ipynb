{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import tiktoken\n",
    "import summary_scripts as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_MODEL = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input functions. \n",
    "\n",
    "### read in es.txt file\n",
    "def read_lines(file):\n",
    "    with open(file) as f:\n",
    "        lines = [l.strip() for l in f.readlines() if '---  page ' not in l and not l.strip() == '']\n",
    "    return lines\n",
    "\n",
    "def read_txt(file):\n",
    "    with open(file) as f:\n",
    "        lines = [l.strip() for l in f.readlines() if '---  page ' not in l and not l.strip() == '']\n",
    "        txt = ' '.join(lines)\n",
    "    return txt\n",
    "\n",
    "### input path to the file\n",
    "def read_html(file):\n",
    "    with open(file, 'r', encoding=\"utf-8\") as f:\n",
    "        t = f.read()\n",
    "    soup = BeautifulSoup(t, 'html.parser')\n",
    "    txt = soup.get_text()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "simple segmentation function \n",
    "segment the long document into chunks of similar size\n",
    "\n",
    "txt: long document\n",
    "CHUNK_SIZE: size of segments\n",
    "return: list of text segments\n",
    "'''\n",
    "\n",
    "def partition_document(txt, CHUNK_SIZE = 5000):\n",
    "    \n",
    "    token_count = ss.count_tokens(txt)\n",
    "\n",
    "    num_segments = int(np.round(token_count / CHUNK_SIZE))\n",
    "    print(num_segments)\n",
    "\n",
    "    char_count = len(txt)\n",
    "    split_length = int(np.round(char_count/num_segments))\n",
    "    # print(split_length)\n",
    "\n",
    "    segments = []\n",
    "    c = 0\n",
    "    head = 0\n",
    "    tail = split_length * 1\n",
    "    temp = tail\n",
    "    find_split = False\n",
    "    while(c < num_segments):\n",
    "        find_split = False\n",
    "        if c == num_segments - 1:\n",
    "            segments.append(txt[head:])\n",
    "            c += 1\n",
    "        else:\n",
    "            while(not find_split):\n",
    "                if txt[temp:temp+2] == '. ':\n",
    "                    tail =  temp + 1\n",
    "                    find_split = True\n",
    "                    segments.append(txt[head:tail])\n",
    "                    head = tail + 1\n",
    "                    temp = head + split_length * 1\n",
    "                    tail = temp\n",
    "                    c += 1\n",
    "                    break\n",
    "                else:\n",
    "                    temp += 1\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_long(mssges, modelname = \"gpt-3.5-turbo-1106\", temp = 1.0,max_tokens = 1000):\n",
    "    '''\n",
    "    a simplified version of get_completion\n",
    "    mssges should be prepared as argument to completion request\n",
    "    '''\n",
    "    completion = client.chat.completions.create(\n",
    "        model=modelname,\n",
    "        messages= mssges,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature = temp)\n",
    "\n",
    "    #print tokens used in prompt and completion\n",
    "    print(\"Tokens in prompt: \", completion.usage.prompt_tokens)\n",
    "    print(\"Tokens in completion: \", completion.usage.completion_tokens)\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary_long(segments,savedir,country,save_result = True,token_limit = 14000, model_name = \"gpt-3.5-turbo-1106\", t = 1.0):\n",
    "    '''\n",
    "    Summarizes a sequence of segments from a large document progressively\n",
    "    \n",
    "\n",
    "    segments: [text1,text2,...], a list of consecutive segments from a long document\n",
    "    savedir: directory where to save the summary and completion object\n",
    "    country: country for which to summarize\n",
    "    token_limit: maximum number of tokens for the text (not used in this case)\n",
    "    modelname: name of the model to use\n",
    "\n",
    "    Returns a list of summaries. The last item is the final and complete version. \n",
    "    '''\n",
    "    ### prepare message for the first segment summary\n",
    "    msgs_start = [{\"role\" : \"system\", \"content\": role_system_bullets}]\n",
    "    content_start = prpt_bullets_ada + segments[0]\n",
    "    msgs_start.append({\"role\" : \"system\", \"content\": content_start})\n",
    "    comp_start = get_completion_long(msgs_start)\n",
    "    print(comp_start.choices[0].message.content)\n",
    "    summary_chain = [] # the list of all segment summaries\n",
    "    summ_temp = comp_start.choices[0].message.content\n",
    "    summary_chain.append(summ_temp)\n",
    "    n_ch = len(segments)\n",
    "    ### progressive summary revision starts\n",
    "    # summary_(i+1) is based on segment_(i+1),summary_(i) \n",
    "    for i in range(n_ch-1):\n",
    "        idx = i + 1\n",
    "        print(\"--- Preparing summary indexed \" + str(idx))\n",
    "        msgs_chain = [{\"role\" : \"system\", \"content\": role_system_bullets_chain}]\n",
    "        content_chain = old_summ_chain + summ_temp + prpt_bullets_ada_chain + segments[idx] + prpt_chain\n",
    "        msgs_chain.append({\"role\" : \"user\", \"content\": content_chain})\n",
    "        comp_chain = get_completion_long(msgs_chain)\n",
    "        summ_temp = comp_chain.choices[0].message.content\n",
    "        completion_dict = ss.convert_chat_completion_to_dict(comp_chain)\n",
    "        print(summ_temp)\n",
    "        summary_chain.append(summ_temp)\n",
    "\n",
    "        if save_result:\n",
    "\n",
    "            savepath_summary = os.path.join(savedir, \"summary_t\" + str(t) + \"_seg\" + str(idx) + \".txt\")\n",
    "            if idx == n_ch - 1:\n",
    "                savepath_summary = os.path.join(savedir, \"summary_t\" + str(t) + \".txt\")\n",
    "            savepath_completion = os.path.join(savedir, \"completion_seg\"+ str(idx)+ \".json\")\n",
    "\n",
    "            completion_json = json.dumps(completion_dict)\n",
    "\n",
    "            #save the summary and the completion object in the savedir\n",
    "\n",
    "            with open(savepath_completion, \"w\") as f:  \n",
    "                f.write(completion_json)\n",
    "\n",
    "            with open(savepath_summary, \"w\") as f:\n",
    "                f.write(summ_temp)\n",
    "    \n",
    "    print(\"Total number of summaries written: \" + str(len(summary_chain)))\n",
    "    return summary_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Prompt engineering\n",
    "\n",
    "##### normal size document prompt\n",
    "role_system_bullets = \"\"\"\n",
    "You are a multi-lingual international lawyer whos legal specialty is data protection and processing.\n",
    "Additionally, you know and work with the General Data Protection Regulations (GDPR) of European Union.\n",
    "You will produce a summary of the document from the data protection authority by answering questions. \n",
    "The summary will be in English only.\n",
    "As a general rule, be clear and precise about your writing. If the answer is unclear, explain how so.\"\"\"\n",
    "prpt_bullets_ada = \"\"\"\"\n",
    "Please finish the tasks one by one.\n",
    "1. In one or two sentences, identify the type of the document.\n",
    "2. Identify the complainant and defendant mentioned in the document, if any. Briefly introduce their roles and functions, if provided by the document. Determine the type of complainant and the type of defendant as individual, or company, or public institution, or public authority. Describe the relationship between these two parties if possible. \n",
    "3. Please elaborate the subject matter of the dispute between these two parties, and then explain the data involved in this dispute.\n",
    "4. What kind of data processing was involved (including but not limited to collection, storage, transfer, publication, dissimation, etc.) and for what purpose (including but not limited to marketing, journalistic purposes, market research, etc.)?\n",
    "5. What articles of GDPR, if any, does the complainant claim that the defendant potentially violates?\n",
    "6. Does the legal authority dismiss the submitted complaint or case? \n",
    "7. What is the outcome of the dispute? From the final resolution in the document, describe all the enforcements by the authority in detail (including but not limited to: fine, warning, investgation and other penalties or obligations)\n",
    "8. What facts and evidence are verified or proved by the authority?\n",
    "9. In case the complaint is approved or the authority releases the enforcement, identify the GDPR articles violated by the defendant, if any. Your answer should only consider the decision made by the data protection authority, together with the verified evidence or facts in the previous steps.\n",
    "10. Is the document a final decision, or a preliminary decision (e.g. an order to stop data processing until a final decision is made), or an intermediate procedural step (e.g. a request for additional information), or related to a previous procedure, or something else?\n",
    "\n",
    "Here is the document:\n",
    "\n",
    "\"\"\"\n",
    "##### progressive summary chain\n",
    "role_system_bullets_chain = \"\"\"You are a multi-lingual international lawyer whos legal specialty is data protection and processing.\n",
    "Additionally, you know and work with the General Data Protection Regulations (GDPR) of European Union.\n",
    "\n",
    "\"\"\"\n",
    "old_summ_chain = \"\"\"\n",
    "You will be given three passages. \n",
    "First, you have a temporary list of responses in bullet points regarding the ealier parts of a legal decision document:\n",
    "\n",
    "\"\"\"\n",
    "prpt_bullets_ada_chain = \"\"\"\n",
    "Second, you have a list of tasks regarding the document as your guidance:\n",
    "1. In one or two sentences, identify the type of the document.\n",
    "2. Identify the complainant and defendant mentioned in the document, if any. Briefly introduce their roles and functions, if provided by the document. Determine the type of complainant and the type of defendant as individual, or company, or public institution, or public authority. Describe the relationship between these two parties if possible. \n",
    "3. Please elaborate the subject matter of the dispute between these two parties, and then explain the data involved in this dispute.\n",
    "4. What kind of data processing was involved (including but not limited to collection, storage, transfer, publication, dissimation, etc.) and for what purpose (including but not limited to marketing, journalistic purposes, market research, etc.)?\n",
    "5. What articles of GDPR, if any, does the complainant claim that the defendant potentially violates?\n",
    "6. Does the legal authority dismiss the submitted complaint or case? \n",
    "7. What is the outcome of the dispute? Describe all the legal enforcements by the authority in detail, including fine, warning, investgation and other penalties or obligations, etc..\n",
    "8. What facts and evidence are verified or proved by the authority?\n",
    "9. In case the complaint is approved or the authority releases the enforcement, identify the GDPR articles violated by the defendant, if any. Your answer should only consider the decision made by the data protection authority, together with the verified evidence or facts in the previous steps.\n",
    "10. Is the document a final decision, or a preliminary decision (e.g. an order to stop data processing until a final decision is made), or an intermediate procedural step (e.g. a request for additional information), or related to a previous procedure, or something else?\n",
    "Lastly, here is the latest segment of the same document from which the temporary summary is produced:\n",
    "\n",
    "\"\"\"\n",
    "prpt_chain = \"\"\"\n",
    "Your job is to review the temporary list of responses and use the list of task prompts and the latest segment of the document to add more definite answers. You will make revisions or additions to the old responses if those answers are uncertain, not mentioned, or unclear, etc... Please output the updated whole list of responses , not only the parts you make revisions.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
